{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9010d41-5560-418b-ba93-65aafe05d357",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'000051650-1_1_1'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('corpus_file.txt', 'r') as corpus_file:\n",
    "    corpus_list = corpus_file.read().splitlines()\n",
    "corpus_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c6143e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8767\n",
      "157822\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'000107696-1_1_1'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_split = 0.1\n",
    "val_idx = int(len(corpus_list) * val_split)\n",
    "training_list = corpus_list[val_idx:]\n",
    "validation_list = corpus_list[:val_idx]\n",
    "\n",
    "# training_list[0]\n",
    "\n",
    "temp = []\n",
    "for item in validation_list:\n",
    "    temp.append(\"D \" + item)\n",
    "validation_list = temp\n",
    "\n",
    "# training_list = corpus_list[1000:11000]\n",
    "# validation_list = corpus_list[:1000]\n",
    "# temp_validation_list = []\n",
    "\n",
    "print(len(validation_list))\n",
    "#Selectively choosing tests based on length:\n",
    "# for item in validation_list:\n",
    "#     with open('DataMach5/Primus/' + item + '/' + item + '.semantic', 'r') as sample_gt_file:\n",
    "#         sample_gt_words = sample_gt_file.readline().rstrip().split('\\t')\n",
    "#         if len(sample_gt_words) <= 20:\n",
    "#             temp_validation_list.append(item)\n",
    "        \n",
    "# validation_list = temp_validation_list\n",
    "# print(len(validation_list))\n",
    "\n",
    "temp = []\n",
    "for item in training_list:\n",
    "    temp.append(\"D \" + item)\n",
    "training_list += temp\n",
    "print(len(training_list))\n",
    "\n",
    "training_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8c4da238-2382-4991-8b06-156f2a2295b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "\n",
    "class PrimusDataset(Dataset):\n",
    "    def __init__(self, root_dir, distorted_dir, df, processor, tokenizer, max_target_length=256, semantic=True):\n",
    "        self.root_dir = root_dir\n",
    "        self.df = df\n",
    "        self.processor = processor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_target_length = max_target_length\n",
    "        self.semantic = semantic\n",
    "        self.distorted_dir = distorted_dir\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        file_name = self.df[idx]\n",
    "        isDistorted = False\n",
    "        if file_name[0] == 'D':\n",
    "            file_name =  file_name[2:]\n",
    "            isDistorted = True\n",
    "        \n",
    "        sample_fullpath = self.root_dir + '/' + file_name + '/' + file_name\n",
    "        if not self.semantic:\n",
    "            sample_gt_fullpath = 'Agnostic_encoding/' + file_name + '/' + file_name + '.agnostic'\n",
    "        else:\n",
    "            sample_gt_fullpath = sample_fullpath + '.semantic'\n",
    "        \n",
    "        with open(sample_gt_fullpath, 'r') as sample_gt_file:\n",
    "            sample_gt_words = sample_gt_file.readline().rstrip().split(self.word_separator())\n",
    "            sample_gt_plain = ' '.join(sample_gt_words)\n",
    "        \n",
    "        if isDistorted:\n",
    "            image = Image.open(self.distorted_dir + file_name + '/' + file_name + '_distorted.jpg').convert('RGB')\n",
    "        else:\n",
    "            image = Image.open(sample_fullpath + '.png').convert('RGB')\n",
    "        \n",
    "        \n",
    "        pixel_values = self.processor(image, return_tensors=\"pt\").pixel_values\n",
    "        \n",
    "        labels = self.tokenizer.tokenize(sample_gt_plain, \n",
    "                                          max_length=self.max_target_length)\n",
    "\n",
    "        labels = [label if label != self.tokenizer.pad_token_id else -100 for label in labels]\n",
    "        encoding = {\"pixel_values\": pixel_values.squeeze(), \"labels\": torch.tensor(labels)}\n",
    "#         print(encoding)\n",
    "        return encoding\n",
    "\n",
    "    @staticmethod\n",
    "    def word_separator():\n",
    "        return '\\t'\n",
    "    \n",
    "#     @staticmethod\n",
    "#     def resize(image, height):\n",
    "#         aspect_ratio = image.width / image.height\n",
    "#         new_width = int(aspect_ratio * height)\n",
    "#         resized_image = image.resize((new_width, height), Image.LANCZOS)\n",
    "#         return resized_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c0c01ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"microsoft/trocr-base-printed\")\n",
    "\n",
    "# word2int = {}\n",
    "\n",
    "# dict_file = open('Data/vocabulary_semantic.txt','r')\n",
    "# dict_list = dict_file.read().splitlines()\n",
    "# i=0\n",
    "# for word in dict_list:\n",
    "#     if not word in word2int:\n",
    "#         word2int[word] = i\n",
    "#         i+=1\n",
    "\n",
    "# dict_file.close()\n",
    "# new_tokens = set(word2int) - set(tokenizer.vocab.keys())\n",
    "# tokenizer.add_tokens(list(new_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1eeceed6-f30e-4d36-a67e-0b1c28959686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<s>', '<pad>', '</s>', '<unk>', 'barline', 'clef-C1', 'clef-C2', 'clef-C3', 'clef-C4', 'clef-C5']\n",
      "[0, 4, 1745, 6, 2, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n",
      "Detokenized text:  barline tie clef-C2\n"
     ]
    }
   ],
   "source": [
    "class SimpleTokenizer:\n",
    "    def __init__(self, vocab, pad_token='<pad>', start_token='<s>', end_token='</s>'):\n",
    "        self.vocab = vocab\n",
    "        self.pad_token_id = vocab[pad_token]\n",
    "        self.cls_token_id = vocab[start_token]\n",
    "        self.sep_token_id = vocab[end_token]\n",
    "        self.inverse_vocab = {v: k for k, v in vocab.items()}\n",
    "\n",
    "    def tokenize(self, text, max_length=None):\n",
    "        token_ids = []\n",
    "        \n",
    "        token_ids.append(self.cls_token_id)\n",
    "        \n",
    "        token_ids.extend(self.vocab[token] if token in self.vocab else self.vocab['<unk>'] for token in text.split())\n",
    "\n",
    "        token_ids.append(self.sep_token_id)\n",
    "        \n",
    "        if max_length is not None:\n",
    "            padding_length = max(0, max_length - len(token_ids))\n",
    "            token_ids.extend([self.pad_token_id] * padding_length)\n",
    "        \n",
    "        return token_ids\n",
    "\n",
    "    def detokenize(self, token_ids):\n",
    "        # Converts a list of token IDs back to a string\n",
    "        # Remove special characters\n",
    "        assert isinstance(token_ids, list), \"token_ids must be a list\"\n",
    "        tokens = [self.inverse_vocab[token_id] for token_id in token_ids if token_id in self.inverse_vocab and token_id not in [self.cls_token_id, self.sep_token_id, self.pad_token_id]]\n",
    "        return ' '.join(tokens)\n",
    "    \n",
    "    def batch_decode(self, batch_token_ids):\n",
    "        assert isinstance(batch_token_ids, list), \"batch_token_ids must be a list\"\n",
    "        decoded_strings = []\n",
    "        for token_ids in batch_token_ids:\n",
    "            decoded_strings.append(self.detokenize(token_ids))\n",
    "        return decoded_strings\n",
    "\n",
    "dict_file = open('vocabulary_semantic_modified.txt','r')\n",
    "# dict_file = open('vocabulary_agnostic_modified.txt','r')\n",
    "dict_list = dict_file.read().splitlines()\n",
    "print(list(dict_list)[:10])\n",
    "dict_file.close()\n",
    "vocab = {tok: i for i, tok in enumerate(dict_list)}\n",
    "tokenizer = SimpleTokenizer(vocab)\n",
    "text = \"barline tie clef-C2\"\n",
    "# text = \"accidental.flat-L4 dot-S-2\"\n",
    "token_ids = tokenizer.tokenize(text, max_length=256)\n",
    "print(token_ids)\n",
    "detokenized_text = tokenizer.detokenize(token_ids)\n",
    "print(\"Detokenized text: \", detokenized_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f705494",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/localscratch/bisman.18554872.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import TrOCRProcessor\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "processor = TrOCRProcessor.from_pretrained(\"microsoft/trocr-small-handwritten\")\n",
    "# processor.feature_extractor.size = (512, 512)\n",
    "# tokenizer = AutoTokenizer.from_pretrained('tokenizer-small-new-only')\n",
    "\n",
    "train_dataset = PrimusDataset(root_dir='DataMach5/Primus',\n",
    "                            distorted_dir='CamPrIMuS/',\n",
    "                           df=training_list,\n",
    "                           processor=processor,\n",
    "                            tokenizer=tokenizer)\n",
    "val_dataset = PrimusDataset(root_dir='DataMach5/Primus',\n",
    "                            distorted_dir='CamPrIMuS/',\n",
    "                           df=validation_list,\n",
    "                           processor=processor,\n",
    "                           tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd99eeef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training examples: 157822\n",
      "Number of validation examples: 8767\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of training examples:\", len(train_dataset))\n",
    "print(\"Number of validation examples:\", len(val_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d72b2b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pixel_values torch.Size([3, 384, 384])\n",
      "labels torch.Size([256])\n"
     ]
    }
   ],
   "source": [
    "encoding = train_dataset[0]\n",
    "for k,v in encoding.items():\n",
    "  print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "669620e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "image/png": "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",
      "text/plain": [
       "<PIL.Image.Image image mode=RGB size=602x149>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image = Image.open(train_dataset.root_dir + '/' + training_list[0] + '/' + training_list[0] + '.png').convert(\"RGB\")\n",
    "image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "758303d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clef-G2 keySignature-BbM timeSignature-C rest-eighth note-G5_eighth barline note-C6_eighth note-G5_eighth note-C5_eighth note-G4_eighth note-C5_eighth note-G4_eighth\n"
     ]
    }
   ],
   "source": [
    "labels = encoding['labels']\n",
    "\n",
    "labels[labels == -100] = tokenizer.pad_token_id\n",
    "label_str = tokenizer.detokenize(labels.tolist())\n",
    "print(label_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "185a0c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64 ,shuffle=True, num_workers = 12)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, num_workers = 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1abdfda0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Error Rate: 0.8333333333333334\n"
     ]
    }
   ],
   "source": [
    "import jiwer\n",
    "\n",
    "# Example usage\n",
    "reference = \"clef-G2 keySignature-BbM   timeSignature-C rest-eighth note-G5_eighth barline note-C6_eighth note-G5_eighth note-C5_eighth note-G4_eighth note-C5_eighth note-G4_eighth\"\n",
    "hypothesis = \" clef-G2   keySignature-BbM\"\n",
    "\n",
    "wer = jiwer.wer(reference, hypothesis)\n",
    "print(\"Word Error Rate:\", wer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "383cc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import VisionEncoderDecoderModel\n",
    "import torch.nn as nn\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c8eb732-0d9c-424a-85a8-7a7eb2c04c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import math\n",
    "# import torch.nn.functional as F\n",
    "# def resize_pos_embed(posemb, new_image_size, patch_size):\n",
    "#     # Calculate the number of patches for the new image size\n",
    "#     new_grid_height = new_image_size[0] // patch_size\n",
    "#     new_grid_width = new_image_size[1] // patch_size\n",
    "#     new_num_patches = new_grid_height * new_grid_width\n",
    "\n",
    "#     cls_token_emb = posemb[:, :2, :]\n",
    "#     posemb_grid = posemb[:, 2:, :]  # Exclude the CLS token\n",
    "\n",
    "#     # Calculate the grid size of the original posemb\n",
    "#     gs_old = int(math.sqrt(posemb_grid.shape[1]))\n",
    "    \n",
    "#     print(\"before initial reshaping\", posemb_grid.shape)\n",
    "\n",
    "#     # Reshape to [1, embedding_dim, height, width]\n",
    "#     posemb_grid = posemb_grid.reshape(1, gs_old, gs_old, -1).permute(0, 3, 1, 2)\n",
    "#     print(\"before interpolate\", posemb_grid.shape)\n",
    "\n",
    "#     # Resize to the new grid size\n",
    "#     posemb_grid = F.interpolate(posemb_grid, size=(new_grid_height, new_grid_width), mode='bicubic', align_corners=False)\n",
    "    \n",
    "#     print(\"after interpolate\", posemb_grid.shape)\n",
    "    \n",
    "#     # Reshape back to [1, num_patches, embedding_dim]\n",
    "#     posemb_grid = posemb_grid.permute(0, 2, 3, 1).reshape(1, new_grid_height*new_grid_width,-1)\n",
    "    \n",
    "#     print(\"after reshaping\", posemb_grid.shape)\n",
    "#     # Concatenate with the CLS token embedding\n",
    "#     new_posemb = torch.cat([cls_token_emb, posemb_grid], dim=1)\n",
    "#     return new_posemb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c6eb1cd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): VisionEncoderDecoderModel(\n",
       "    (encoder): DeiTModel(\n",
       "      (embeddings): DeiTEmbeddings(\n",
       "        (patch_embeddings): DeiTPatchEmbeddings(\n",
       "          (projection): Conv2d(3, 384, kernel_size=(16, 16), stride=(16, 16))\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "      (encoder): DeiTEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0-11): 12 x DeiTLayer(\n",
       "            (attention): DeiTAttention(\n",
       "              (attention): DeiTSelfAttention(\n",
       "                (query): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (key): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (value): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): DeiTSelfOutput(\n",
       "                (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): DeiTIntermediate(\n",
       "              (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "            )\n",
       "            (output): DeiTOutput(\n",
       "              (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "            (layernorm_before): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "            (layernorm_after): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((384,), eps=1e-12, elementwise_affine=True)\n",
       "      (pooler): DeiTPooler(\n",
       "        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "    (decoder): TrOCRForCausalLM(\n",
       "      (model): TrOCRDecoderWrapper(\n",
       "        (decoder): TrOCRDecoder(\n",
       "          (embed_tokens): Embedding(762, 256, padding_idx=1)\n",
       "          (embed_positions): TrOCRLearnedPositionalEmbedding(514, 256)\n",
       "          (layernorm_embedding): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (layers): ModuleList(\n",
       "            (0-5): 6 x TrOCRDecoderLayer(\n",
       "              (self_attn): TrOCRAttention(\n",
       "                (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (activation_fn): ReLU()\n",
       "              (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (encoder_attn): TrOCRAttention(\n",
       "                (k_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "                (v_proj): Linear(in_features=384, out_features=256, bias=True)\n",
       "                (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "              (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "              (fc1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (fc2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (output_projection): Linear(in_features=256, out_features=762, bias=False)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import VisionEncoderDecoderConfig, VisionEncoderDecoderModel, DeiTConfig, TrOCRForCausalLM\n",
    "\n",
    "# model = VisionEncoderDecoderModel.from_pretrained(\"model_trocr-small-stage1\")\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"microsoft/trocr-small-stage1\")\n",
    "# config = VisionEncoderDecoderConfig.from_pretrained(\"model_trocr-small-stage1\")\n",
    "\n",
    "\n",
    "# decoder = BartModel.from_pretrained(\"decoder-BART\").decoder\n",
    "# encoder = VisionEncoderDecoderModel.from_pretrained(\"model_trocr-small-stage1\").encoder\n",
    "# model = VisionEncoderDecoderModel(encoder=encoder, decoder=decoder)\n",
    "# config = VisionEncoderDecoderConfig.from_pretrained(\"model_trocr-small-stage1\")\n",
    "# model = VisionEncoderDecoderModel(config)\n",
    "\n",
    "# replace_relu_with_leaky_relu(model)\n",
    "model.decoder.resize_token_embeddings(len(tokenizer.vocab))\n",
    "# model.encoder.encoder.layer = nn.ModuleList(model.encoder.encoder.layer[:-6])\n",
    "# print(model.config.encoder.num_hidden_layers)\n",
    "# model.config.encoder.num_hidden_layers = 6\n",
    "# model.decoder.layers = nn.ModuleList(model.decoder.layers[:6])\n",
    "# print(model.config.decoder.num_hidden_layers)\n",
    "# model.config.decoder.num_hidden_layers = 6\n",
    "model= nn.DataParallel(model)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe61134a-cbe9-4971-b310-fb2bedcce25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import VisionEncoderDecoderConfig, VisionEncoderDecoderModel, DeiTModel\n",
    "\n",
    "# encoder = VisionEncoderDecoderModel.from_pretrained(\"model_trocr-small-stage1\").encoder\n",
    "# state_dict = encoder.state_dict()\n",
    "# config = VisionEncoderDecoderConfig.from_pretrained(\"model_trocr-small-stage1\").encoder\n",
    "# config.image_size = (512,512)\n",
    "# new_encoder = DeiTModel(config=config)\n",
    "\n",
    "# # update state_dict\n",
    "# new_state_dict = state_dict.copy()\n",
    "# old_posemb = new_state_dict['embeddings.position_embeddings']\n",
    "# print(old_posemb.shape)\n",
    "# new_posemb = resize_pos_embed(old_posemb, new_image_size=(512, 512), patch_size=16) # use PyTorch function linked above\n",
    "# print(new_posemb.shape)\n",
    "# new_state_dict['embeddings.position_embeddings'] = new_posemb\n",
    "# new_encoder.load_state_dict(new_state_dict)\n",
    "\n",
    "# decoder = VisionEncoderDecoderModel.from_pretrained(\"model_trocr-small-stage1\").decoder\n",
    "# model = VisionEncoderDecoderModel(encoder=new_encoder, decoder=decoder)\n",
    "# print(model.encoder.embeddings.position_embeddings.shape)\n",
    "# # Load the model with the updated configuration\n",
    "# model.decoder.resize_token_embeddings(len(tokenizer))\n",
    "# # model.encoder.encoder.layer = nn.ModuleList(model.encoder.encoder.layer[:-8])\n",
    "# # model.decoder.model.decoder.layers = nn.ModuleList(model.decoder.model.decoder.layers[:-8])\n",
    "# model= nn.DataParallel(model)\n",
    "# model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "15388f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_wer(pred_ids_list, label_ids_list):\n",
    "    pred_ids_list = pred_ids_list.tolist()\n",
    "    label_ids_list = label_ids_list.tolist()\n",
    "\n",
    "    total_wer = 0\n",
    "    total_errors = 0\n",
    "    for pred_ids, label_ids in zip(pred_ids_list, label_ids_list):\n",
    "        pred_str = tokenizer.detokenize(pred_ids)\n",
    "        label_ids[label_ids == -100] = tokenizer.pad_token_id  # Handle ignore index\n",
    "        label_str = tokenizer.detokenize(label_ids)\n",
    "        temp = jiwer.wer(label_str, pred_str)\n",
    "        total_wer += temp\n",
    "        if temp > 0 :\n",
    "            total_errors += 1\n",
    "        \n",
    "    average_wer = total_wer / len(pred_ids_list)\n",
    "\n",
    "    return (average_wer , total_errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adc00c32-d51e-43aa-9a3b-2086971da560",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "137"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "07e59618",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.module.config.decoder_start_token_id = tokenizer.cls_token_id\n",
    "model.module.config.pad_token_id = tokenizer.pad_token_id\n",
    "model.module.config.vocab_size = model.module.config.decoder.vocab_size\n",
    "\n",
    "\n",
    "model.module.config.eos_token_id = tokenizer.sep_token_id\n",
    "model.module.config.max_length = 256\n",
    "model.module.config.early_stopping = True\n",
    "model.module.config.no_repeat_ngram_size = 6\n",
    "model.module.config.length_penalty = 6.0\n",
    "model.module.config.num_beams = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "591502a7-bdb5-42ee-a6b2-9279ab8617c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25db59",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [34:17<00:00,  1.20it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n",
      "Your generation config was originally created from the model config, but the model config has changed since then. Unless you pass the `generation_config` argument to this model's `generate` calls, they will revert to the legacy behavior where the base `generate` parameterization is loaded from the model config instead. To avoid this behavior and this warning, we recommend you to overwrite the generation config model attribute before calling the model's `save_pretrained`, preferably also removing any generation kwargs from the model config. This warning will be raised to an exception in v4.41.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 1: 3.589105556481076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/137 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/transformers/generation/utils.py:1197: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use and modify the model generation configuration (see https://huggingface.co/docs/transformers/generation_strategies#default-text-generation-configuration )\n",
      "  warnings.warn(\n",
      "100%|| 2466/2466 [42:25<00:00,  1.03s/it]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 14: 0.10017038401841682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:59<00:00,  4.38s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 14: 0.0330972482209662\n",
      "Sequences with error(s): 2935\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [45:11<00:00,  1.10s/it]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 15: 0.08912769914887972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [10:08<00:00,  4.44s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 15: 0.028448373769031206\n",
      "Sequences with error(s): 2664\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [35:11<00:00,  1.17it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 16: 0.07859715307320242\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [10:43<00:00,  4.70s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 16: 0.02675870801385226\n",
      "Sequences with error(s): 2536\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [34:46<00:00,  1.18it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 17: 0.07159653272923906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:48<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 17: 0.026185994428636755\n",
      "Sequences with error(s): 2487\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [36:10<00:00,  1.14it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 18: 0.0643137203663926\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [10:16<00:00,  4.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 18: 0.025920640845020333\n",
      "Sequences with error(s): 2533\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [36:24<00:00,  1.13it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 19: 0.06564850973256918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:49<00:00,  4.30s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 19: 0.02998853328274336\n",
      "Sequences with error(s): 2817\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [37:34<00:00,  1.09it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 20: 0.0499016236984424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:58<00:00,  4.37s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 20: 0.030499680073096298\n",
      "Sequences with error(s): 2919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [36:14<00:00,  1.13it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 30: 0.027781858674491493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:51<00:00,  4.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 30: 0.022338010209938246\n",
      "Sequences with error(s): 2241\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [33:38<00:00,  1.22it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 31: 0.015299469274102384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 31: 0.019357132495114136\n",
      "Sequences with error(s): 1994\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [32:19<00:00,  1.27it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 32: 0.014068745656655791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:39<00:00,  4.23s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 32: 0.01879812035326849\n",
      "Sequences with error(s): 1951\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 28%|       | 698/2466 [09:20<19:18,  1.53it/s]  IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "100%|| 137/137 [09:31<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 33: 0.018414213311928298\n",
      "Sequences with error(s): 1914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [31:51<00:00,  1.29it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 34: 0.012725740090639096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:29<00:00,  4.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 34: 0.01895560324165666\n",
      "Sequences with error(s): 1965\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [36:19<00:00,  1.13it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 35: 0.012283540798943348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:31<00:00,  4.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 35: 0.018740226114244536\n",
      "Sequences with error(s): 1942\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [36:47<00:00,  1.12it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 36: 0.011906339270347881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:26<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 36: 0.018493398223403307\n",
      "Sequences with error(s): 1918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [31:39<00:00,  1.30it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 65: 0.009937709641300327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:25<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 65: 0.018477441658884396\n",
      "Sequences with error(s): 1919\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [30:50<00:00,  1.33it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 66: 0.009909846195326068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:24<00:00,  4.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 66: 0.01851758302839631\n",
      "Sequences with error(s): 1921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [30:56<00:00,  1.33it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 67: 0.009918985849320782\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:26<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 67: 0.0184719300504211\n",
      "Sequences with error(s): 1920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [33:48<00:00,  1.22it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 68: 0.009919977700026193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:43<00:00,  4.26s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 68: 0.018505984590216493\n",
      "Sequences with error(s): 1921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [35:20<00:00,  1.16it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 69: 0.009963344874882818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:27<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 69: 0.018415069475524133\n",
      "Sequences with error(s): 1913\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [31:13<00:00,  1.32it/s] \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 70: 0.009930593622476391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 70: 0.01847088706228133\n",
      "Sequences with error(s): 1922\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [28:34<00:00,  1.44it/s] \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 71: 0.00990409939634838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 71: 0.01843828456336233\n",
      "Sequences with error(s): 1918\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 137/137 [09:32<00:00,  4.18s/it]s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 73: 0.018447400425934554\n",
      "Sequences with error(s): 1921\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [32:59<00:00,  1.25it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 74: 0.00989196885863224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:29<00:00,  4.15s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 74: 0.01844637343157675\n",
      "Sequences with error(s): 1920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [29:34<00:00,  1.39it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 75: 0.009907520830854834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:26<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 75: 0.018501565650363594\n",
      "Sequences with error(s): 1923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [31:36<00:00,  1.30it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 76: 0.00990074714596647\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:25<00:00,  4.13s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 76: 0.018470618774115932\n",
      "Sequences with error(s): 1923\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [32:21<00:00,  1.27it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 77: 0.009934617860381705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [10:06<00:00,  4.43s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 77: 0.018482229426531726\n",
      "Sequences with error(s): 1920\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "100%|| 2466/2466 [34:01<00:00,  1.21it/s]  \n",
      "Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\n",
      "Non-default generation parameters: {'max_length': 256, 'early_stopping': True, 'num_beams': 4, 'length_penalty': 6.0, 'no_repeat_ngram_size': 6}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loss after epoch 78: 0.009866631447733362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:27<00:00,  4.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "val dataloader length 137\n",
      "Validation SER after epoch 78: 0.0184165717970736\n",
      "Sequences with error(s): 1914\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2466 [00:00<?, ?it/s]/localscratch/bisman.18348683.0/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      " 61%|    | 1509/2466 [19:27<10:18,  1.55it/s]  "
     ]
    }
   ],
   "source": [
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "\n",
    "# optimizer = AdamW(model.parameters(), lr=5e-5, weight_decay=0.01)\n",
    "optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "scheduler = ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "for epoch in range(80):  #Change back to (40)\n",
    "   # train\n",
    "   model.train()\n",
    "   train_loss = 0.0\n",
    "   for batch in tqdm(train_dataloader):\n",
    "      # get the inputs\n",
    "#       print(batch)\n",
    "      for k,v in batch.items():\n",
    "        batch[k] = v.to(device)\n",
    "      # outputs = model(**batch)\n",
    "      outputs = model(pixel_values=batch['pixel_values'], labels=batch['labels'])\n",
    "      loss = outputs.loss\n",
    "      loss=loss.mean()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "      optimizer.zero_grad()\n",
    "\n",
    "      train_loss += loss.item()\n",
    "   display_result = f\" Loss after epoch {epoch+1}: {train_loss/len(train_dataloader)}\"\n",
    "   print(display_result)\n",
    "   model.module.save_pretrained(f\"epoch_mach3_base4/epoch_{epoch + 1}\")\n",
    "   with open(\"epoch_mach3_base4/results.txt\", \"a\") as myfile:\n",
    "        myfile.write(display_result)\n",
    "    \n",
    "   # validation\n",
    "   model.eval()\n",
    "   valid_wer = 0.0\n",
    "   valid_seq_err = 0\n",
    "   with torch.no_grad():\n",
    "     for batch in tqdm(val_dataloader):\n",
    "       # run batch generation\n",
    "       outputs = model.module.generate(batch[\"pixel_values\"].to(device))\n",
    "       # compute WER (or SER)\n",
    "       wer, seq_err = compute_wer(pred_ids_list=outputs, label_ids_list=batch[\"labels\"])\n",
    "       valid_seq_err += seq_err\n",
    "       valid_wer += wer \n",
    "   scheduler.step(valid_wer / len(val_dataloader))\n",
    "   print(\"val dataloader length\", len(val_dataloader))\n",
    "   display_result = f\"Validation SER after epoch {epoch+1}: {valid_wer / len(val_dataloader)}\\nSequences with error(s): {valid_seq_err}\\n\"\n",
    "   print(display_result)\n",
    "   with open(\"epoch_mach3_base4/results.txt\", \"a\") as myfile:\n",
    "        myfile.write(display_result)\n",
    "\n",
    "model.module.save_pretrained(\"./trained_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efc0f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e989e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7360d6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 137/137 [09:56<00:00,  4.36s/it]\n"
     ]
    }
   ],
   "source": [
    "# from transformers import VisionEncoderDecoderModel\n",
    "# from tqdm import tqdm\n",
    "# tempmodel = VisionEncoderDecoderModel.from_pretrained(\"epoch_mach3_base4/epoch_41\")\n",
    "# print(tempmodel.config.max_length)\n",
    "# import torch.nn as nn\n",
    "# tempmodel= nn.DataParallel(tempmodel)\n",
    "# tempmodel.to(device)\n",
    "# valid_wer = 0.0\n",
    "# valid_seq_err = 0\n",
    "# error_sequences = 0\n",
    "# with torch.no_grad():\n",
    "#     for batch in tqdm(val_dataloader):\n",
    "#    # run batch generation\n",
    "#         outputs = tempmodel.module.generate(batch[\"pixel_values\"].to(device), num_beams=4, early_stopping=False, length_penalty = 2, max_length = 256)\n",
    "#    # compute WER (or SER)\n",
    "#         wer, seq_err = compute_wer(pred_ids_list=outputs, label_ids_list=batch[\"labels\"])\n",
    "#         valid_seq_err += seq_err\n",
    "#         valid_wer += wer \n",
    "\n",
    "# final_test = f\" Final Validation WER beams=4 :  {valid_wer / len(val_dataloader)} ; Sequences Errors: {error_sequences} \"\n",
    "# with open(\"epoch_mach3_base/results.txt\", \"a\") as myfile:\n",
    "#         myfile.write(final_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae7bb2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(final_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
